{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQOx9I2Nj1y0Bn7gaqOcHt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srigit-dot/machine-learning/blob/main/CAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 587
        },
        "id": "aFbaNXzyQg1T",
        "outputId": "7c24bd53-d173-47a5-e1cb-2b4b97a05cc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 4s/step - accuracy: 0.1531 - loss: 2.3207\n",
            "\n",
            "üî¢ Enter an index from test set (0-9999): 5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 129504 (\\N{BRAIN}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Load and preprocess MNIST data\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "x_train = x_train.astype(\"float32\") / 255.\n",
        "x_test = x_test.astype(\"float32\") / 255.\n",
        "\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, 10)\n",
        "y_test = keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "# --- Capsule Layers and Squash ---\n",
        "\n",
        "def squash_fn(vectors, axis=-1):\n",
        "    s_squared_norm = tf.reduce_sum(tf.square(vectors), axis, keepdims=True)\n",
        "    scale = s_squared_norm / (1 + s_squared_norm)\n",
        "    return scale * vectors / tf.sqrt(s_squared_norm + 1e-9)\n",
        "\n",
        "class Squash(layers.Layer):\n",
        "    def call(self, inputs, **kwargs):\n",
        "        return squash_fn(inputs)\n",
        "\n",
        "class Length(layers.Layer):\n",
        "    def call(self, inputs, **kwargs):\n",
        "        return tf.sqrt(tf.reduce_sum(tf.square(inputs), -1) + 1e-9)\n",
        "\n",
        "class CapsuleLayer(layers.Layer):\n",
        "    def __init__(self, num_capsules, dim_capsule, routings=3, **kwargs):\n",
        "        super(CapsuleLayer, self).__init__(**kwargs)\n",
        "        self.num_capsules = num_capsules\n",
        "        self.dim_capsule = dim_capsule\n",
        "        self.routings = routings\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.input_num_capsules = input_shape[1]\n",
        "        self.input_dim_capsule = input_shape[2]\n",
        "        self.W = self.add_weight(\n",
        "            shape=[self.input_num_capsules, self.num_capsules, self.input_dim_capsule, self.dim_capsule],\n",
        "            initializer='glorot_uniform',\n",
        "            trainable=True\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # inputs shape: [batch_size, input_num_capsules, input_dim_capsule]\n",
        "        inputs_expand = tf.expand_dims(inputs, 2)  # [batch, input_caps, 1, dim_caps]\n",
        "        inputs_tiled = tf.expand_dims(inputs_expand, 3)  # [batch, input_caps, 1, 1, dim_caps]\n",
        "\n",
        "        # W shape: [input_caps, output_caps, input_dim, output_dim]\n",
        "        W_tiled = tf.expand_dims(self.W, 0)  # [1, input_caps, output_caps, input_dim, output_dim]\n",
        "        u_hat = tf.matmul(inputs_tiled, W_tiled)  # [batch, input_caps, output_caps, 1, output_dim]\n",
        "        u_hat = tf.squeeze(u_hat, axis=3)  # [batch, input_caps, output_caps, output_dim]\n",
        "\n",
        "        b = tf.zeros_like(u_hat[..., 0])  # [batch, input_caps, output_caps]\n",
        "\n",
        "        for i in range(self.routings):\n",
        "            c = tf.nn.softmax(b, axis=2)  # softmax over output_caps\n",
        "            outputs = squash_fn(tf.reduce_sum(c[..., None] * u_hat, axis=1))  # [batch, output_caps, output_dim]\n",
        "            if i < self.routings - 1:\n",
        "                b += tf.reduce_sum(u_hat * outputs[:, None, :, :], axis=-1)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "# --- Build Capsule Model ---\n",
        "inputs = keras.Input(shape=(28, 28, 1))\n",
        "x = layers.Conv2D(256, 9, activation='relu')(inputs)\n",
        "x = layers.Conv2D(32 * 8, 9, strides=2, activation='relu')(x)\n",
        "x = layers.Reshape((-1, 8))(x)  # 1152 primary capsules, each with 8D\n",
        "x = Squash()(x)\n",
        "\n",
        "caps = CapsuleLayer(num_capsules=10, dim_capsule=16)(x)\n",
        "outputs = Length()(caps)\n",
        "\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# --- Train Model (small subset for quick test) ---\n",
        "model.fit(x_train[:1024], y_train[:1024], batch_size=64, epochs=1)\n",
        "\n",
        "# --- User Input for Prediction ---\n",
        "index = int(input(\"\\nüî¢ Enter an index from test set (0-9999): \"))\n",
        "while not (0 <= index < len(x_test)):\n",
        "    index = int(input(\"Please enter a valid index: \"))\n",
        "\n",
        "sample = np.expand_dims(x_test[index], axis=0)\n",
        "prediction = model.predict(sample)\n",
        "predicted_digit = np.argmax(prediction)\n",
        "\n",
        "# --- Display Prediction ---\n",
        "plt.imshow(x_test[index].reshape(28,28), cmap='gray')\n",
        "plt.title(f\"üß† Predicted Digit: {predicted_digit}\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    }
  ]
}