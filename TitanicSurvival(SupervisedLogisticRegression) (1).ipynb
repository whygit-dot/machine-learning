{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLNQxVUYJIAJ"
      },
      "outputs": [],
      "source": [
        "{\n",
        "  \"nbformat\": 4,\n",
        "  \"nbformat_minor\": 0,\n",
        "  \"metadata\": {\n",
        "    \"colab\": {\n",
        "      \"provenance\": [],\n",
        "      \"authorship_tag\": \"ABX9TyM+wfHNdRA+7l1O5V3pmCbN\",\n",
        "      \"include_colab_link\": true\n",
        "    },\n",
        "    \"kernelspec\": {\n",
        "      \"name\": \"python3\",\n",
        "      \"display_name\": \"Python 3\"\n",
        "    },\n",
        "    \"language_info\": {\n",
        "      \"name\": \"python\"\n",
        "    }\n",
        "  },\n",
        "  \"cells\": [\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"view-in-github\",\n",
        "        \"colab_type\": \"text\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"<a href=\\\"https://colab.research.google.com/github/srigit-dot/machine-learning/blob/main/TitanicSurvival(SupervisedLogisticRegression).ipynb\\\" target=\\\"_parent\\\"><img src=\\\"https://colab.research.google.com/assets/colab-badge.svg\\\" alt=\\\"Open In Colab\\\"/></a>\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"execution_count\": 1,\n",
        "      \"metadata\": {\n",
        "        \"colab\": {\n",
        "          \"base_uri\": \"https://localhost:8080/\",\n",
        "          \"height\": 1000\n",
        "        },\n",
        "        \"id\": \"R6H2oQ8Q8sa8\",\n",
        "        \"outputId\": \"809f8d0c-3982-49b1-b0b8-474207bcc6a8\"\n",
        "      },\n",
        "      \"outputs\": [\n",
        "        {\n",
        "          \"output_type\": \"stream\",\n",
        "          \"name\": \"stdout\",\n",
        "          \"text\": [\n",
        "            \"Collecting gradio\\n\",\n",
        "            \"  Downloading gradio-5.25.0-py3-none-any.whl.metadata (16 kB)\\n\",\n",
        "            \"Collecting aiofiles<25.0,>=22.0 (from gradio)\\n\",\n",
        "            \"  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\\n\",\n",
        "            \"Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\\n\",\n",
        "            \"Collecting fastapi<1.0,>=0.115.2 (from gradio)\\n\",\n",
        "            \"  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\\n\",\n",
        "            \"Collecting ffmpy (from gradio)\\n\",\n",
        "            \"  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\\n\",\n",
        "            \"Collecting gradio-client==1.8.0 (from gradio)\\n\",\n",
        "            \"  Downloading gradio_client-1.8.0-py3-none-any.whl.metadata (7.1 kB)\\n\",\n",
        "            \"Collecting groovy~=0.1 (from gradio)\\n\",\n",
        "            \"  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\\n\",\n",
        "            \"Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\\n\",\n",
        "            \"Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.30.1)\\n\",\n",
        "            \"Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\\n\",\n",
        "            \"Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\\n\",\n",
        "            \"Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\\n\",\n",
        "            \"Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.16)\\n\",\n",
        "            \"Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\\n\",\n",
        "            \"Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\\n\",\n",
        "            \"Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\\n\",\n",
        "            \"Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.2)\\n\",\n",
        "            \"Collecting pydub (from gradio)\\n\",\n",
        "            \"  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\\n\",\n",
        "            \"Collecting python-multipart>=0.0.18 (from gradio)\\n\",\n",
        "            \"  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\\n\",\n",
        "            \"Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\\n\",\n",
        "            \"Collecting ruff>=0.9.3 (from gradio)\\n\",\n",
        "            \"  Downloading ruff-0.11.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\\n\",\n",
        "            \"Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\\n\",\n",
        "            \"  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\\n\",\n",
        "            \"Collecting semantic-version~=2.0 (from gradio)\\n\",\n",
        "            \"  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\\n\",\n",
        "            \"\\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /simple/starlette/\\u001b[0m\\u001b[33m\\n\",\n",
        "            \"\\u001b[0mCollecting starlette<1.0,>=0.40.0 (from gradio)\\n\",\n",
        "            \"  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\\n\",\n",
        "            \"Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\\n\",\n",
        "            \"  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\\n\",\n",
        "            \"Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\\n\",\n",
        "            \"Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.1)\\n\",\n",
        "            \"Collecting uvicorn>=0.14.0 (from gradio)\\n\",\n",
        "            \"  Downloading uvicorn-0.34.1-py3-none-any.whl.metadata (6.5 kB)\\n\",\n",
        "            \"Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (2025.3.2)\\n\",\n",
        "            \"Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (15.0.1)\\n\",\n",
        "            \"Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\\n\",\n",
        "            \"Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\\n\",\n",
        "            \"Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\\n\",\n",
        "            \"Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\\n\",\n",
        "            \"Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\\n\",\n",
        "            \"Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\\n\",\n",
        "            \"Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\\n\",\n",
        "            \"Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\\n\",\n",
        "            \"Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\\n\",\n",
        "            \"Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\\n\",\n",
        "            \"Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\\n\",\n",
        "            \"Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\\n\",\n",
        "            \"Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.1)\\n\",\n",
        "            \"Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\\n\",\n",
        "            \"Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\\n\",\n",
        "            \"Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\\n\",\n",
        "            \"Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\\n\",\n",
        "            \"Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\\n\",\n",
        "            \"Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\\n\",\n",
        "            \"Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\\n\",\n",
        "            \"Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\\n\",\n",
        "            \"Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\\n\",\n",
        "            \"Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\\n\",\n",
        "            \"Downloading gradio-5.25.0-py3-none-any.whl (46.9 MB)\\n\",\n",
        "            \"\\u001b[2K   \\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m \\u001b[32m46.9/46.9 MB\\u001b[0m \\u001b[31m11.6 MB/s\\u001b[0m eta \\u001b[36m0:00:00\\u001b[0m\\n\",\n",
        "            \"\\u001b[?25hDownloading gradio_client-1.8.0-py3-none-any.whl (322 kB)\\n\",\n",
        "            \"\\u001b[2K   \\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m \\u001b[32m322.2/322.2 kB\\u001b[0m \\u001b[31m12.4 MB/s\\u001b[0m eta \\u001b[36m0:00:00\\u001b[0m\\n\",\n",
        "            \"\\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\\n\",\n",
        "            \"Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\\n\",\n",
        "            \"\\u001b[2K   \\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m \\u001b[32m95.2/95.2 kB\\u001b[0m \\u001b[31m6.0 MB/s\\u001b[0m eta \\u001b[36m0:00:00\\u001b[0m\\n\",\n",
        "            \"\\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\\n\",\n",
        "            \"Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\\n\",\n",
        "            \"Downloading ruff-0.11.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.4 MB)\\n\",\n",
        "            \"\\u001b[2K   \\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m \\u001b[32m11.4/11.4 MB\\u001b[0m \\u001b[31m43.6 MB/s\\u001b[0m eta \\u001b[36m0:00:00\\u001b[0m\\n\",\n",
        "            \"\\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\\n\",\n",
        "            \"Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\\n\",\n",
        "            \"Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\\n\",\n",
        "            \"\\u001b[2K   \\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m \\u001b[32m72.0/72.0 kB\\u001b[0m \\u001b[31m3.6 MB/s\\u001b[0m eta \\u001b[36m0:00:00\\u001b[0m\\n\",\n",
        "            \"\\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\\n\",\n",
        "            \"Downloading uvicorn-0.34.1-py3-none-any.whl (62 kB)\\n\",\n",
        "            \"\\u001b[2K   \\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m \\u001b[32m62.4/62.4 kB\\u001b[0m \\u001b[31m3.0 MB/s\\u001b[0m eta \\u001b[36m0:00:00\\u001b[0m\\n\",\n",
        "            \"\\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\\n\",\n",
        "            \"Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\\n\",\n",
        "            \"Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\\n\",\n",
        "            \"Successfully installed aiofiles-24.1.0 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.25.0 gradio-client-1.8.0 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.5 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.2 tomlkit-0.13.2 uvicorn-0.34.1\\n\",\n",
        "            \"Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\\n\",\n",
        "            \"\\n\",\n",
        "            \"Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\\n\",\n",
        "            \"* Running on public URL: https://9875412678e14a60d5.gradio.live\\n\",\n",
        "            \"\\n\",\n",
        "            \"This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\\n\"\n",
        "          ]\n",
        "        },\n",
        "        {\n",
        "          \"output_type\": \"display_data\",\n",
        "          \"data\": {\n",
        "            \"text/plain\": [\n",
        "              \"<IPython.core.display.HTML object>\"\n",
        "            ],\n",
        "            \"text/html\": [\n",
        "              \"<div><iframe src=\\\"https://9875412678e14a60d5.gradio.live\\\" width=\\\"100%\\\" height=\\\"500\\\" allow=\\\"autoplay; camera; microphone; clipboard-read; clipboard-write;\\\" frameborder=\\\"0\\\" allowfullscreen></iframe></div>\"\n",
        "            ]\n",
        "          },\n",
        "          \"metadata\": {}\n",
        "        },\n",
        "        {\n",
        "          \"output_type\": \"execute_result\",\n",
        "          \"data\": {\n",
        "            \"text/plain\": []\n",
        "          },\n",
        "          \"metadata\": {},\n",
        "          \"execution_count\": 1\n",
        "        }\n",
        "      ],\n",
        "      \"source\": [\n",
        "        \"!pip install gradio\\n\",\n",
        "        \"import gradio as gr\\n\",\n",
        "        \"import numpy as np\\n\",\n",
        "        \"import pandas as pd\\n\",\n",
        "        \"from sklearn.model_selection import train_test_split\\n\",\n",
        "        \"from sklearn.preprocessing import StandardScaler, LabelEncoder\\n\",\n",
        "        \"from sklearn.linear_model import LogisticRegression\\n\",\n",
        "        \"import seaborn as sns\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Load Titanic dataset\\n\",\n",
        "        \"df = sns.load_dataset(\\\"titanic\\\")\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Select relevant features & drop missing values\\n\",\n",
        "        \"df = df[['sex', 'age', 'fare', 'pclass', 'embarked', 'survived']].dropna()\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Encode categorical variables\\n\",\n",
        "        \"sex_encoder = {'female': 0, 'male': 1}\\n\",\n",
        "        \"embarked_encoder = {'C': 0, 'Q': 1, 'S': 2}\\n\",\n",
        "        \"\\n\",\n",
        "        \"df['sex'] = df['sex'].map(sex_encoder)\\n\",\n",
        "        \"df['embarked'] = df['embarked'].map(embarked_encoder)\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Define features & target\\n\",\n",
        "        \"X = df[['sex', 'age', 'fare', 'pclass', 'embarked']]\\n\",\n",
        "        \"y = df['survived']  # 0 = Did not survive, 1 = Survived\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Standardize features\\n\",\n",
        "        \"scaler = StandardScaler()\\n\",\n",
        "        \"X_scaled = scaler.fit_transform(X)\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Train-test split\\n\",\n",
        "        \"X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Train Logistic Regression model\\n\",\n",
        "        \"model = LogisticRegression()\\n\",\n",
        "        \"model.fit(X_train, y_train)\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Define the prediction function\\n\",\n",
        "        \"def predict_survival(sex, age, fare, pclass, embarked):\\n\",\n",
        "        \"    try:\\n\",\n",
        "        \"        # Convert categorical inputs to numerical values\\n\",\n",
        "        \"        sex_dict = {\\\"female\\\": 0, \\\"male\\\": 1}\\n\",\n",
        "        \"        embarked_dict = {\\\"C\\\": 0, \\\"Q\\\": 1, \\\"S\\\": 2}\\n\",\n",
        "        \"\\n\",\n",
        "        \"        sex = sex_dict.get(sex, 0)  # Default to 0 if not found\\n\",\n",
        "        \"        embarked = embarked_dict.get(embarked, 2)  # Default to \\\"S\\\"\\n\",\n",
        "        \"\\n\",\n",
        "        \"        # Convert other inputs to float\\n\",\n",
        "        \"        age = float(age)\\n\",\n",
        "        \"        fare = float(fare)\\n\",\n",
        "        \"        pclass = float(pclass)\\n\",\n",
        "        \"\\n\",\n",
        "        \"        # Prepare input for model\\n\",\n",
        "        \"        input_data = np.array([[sex, age, fare, pclass, embarked]])\\n\",\n",
        "        \"        scaled_data = scaler.transform(input_data)  # Standardize\\n\",\n",
        "        \"\\n\",\n",
        "        \"        # Get prediction\\n\",\n",
        "        \"        prediction = model.predict(scaled_data)\\n\",\n",
        "        \"        return \\\"Survived\\\" if prediction[0] == 1 else \\\"Did Not Survive\\\"\\n\",\n",
        "        \"\\n\",\n",
        "        \"    except Exception as e:\\n\",\n",
        "        \"        return f\\\"Error: {e}\\\"  # Display actual error message in UI\\n\",\n",
        "        \"\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Gradio inputs (Fixed categorical mapping)\\n\",\n",
        "        \"input_features = [\\n\",\n",
        "        \"    gr.Radio(choices=['female', 'male'], label=\\\"Sex\\\"),\\n\",\n",
        "        \"    gr.Slider(minimum=1, maximum=80, value=30, label=\\\"Age\\\"),\\n\",\n",
        "        \"    gr.Slider(minimum=0, maximum=500, value=50, label=\\\"Fare Paid\\\"),\\n\",\n",
        "        \"    gr.Radio(choices=[1, 2, 3], label=\\\"Passenger Class\\\"),\\n\",\n",
        "        \"    gr.Radio(choices=['C', 'Q', 'S'], label=\\\"Embarked From\\\"),\\n\",\n",
        "        \"]\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Output display\\n\",\n",
        "        \"output = gr.Textbox()\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Create Gradio interface\\n\",\n",
        "        \"interface = gr.Interface(\\n\",\n",
        "        \"    fn=predict_survival,\\n\",\n",
        "        \"    inputs=input_features,\\n\",\n",
        "        \"    outputs=output,\\n\",\n",
        "        \"    title=\\\"🚢 Titanic Survival Prediction\\\",\\n\",\n",
        "        \"    description=\\\"Enter passenger details to predict if they survived the Titanic disaster.\\\"\\n\",\n",
        "        \")\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Launch Gradio app\\n\",\n",
        "        \"interface.launch()\\n\"\n",
        "      ]\n",
        "    }\n",
        "  ]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "  \"nbformat\": 4,\n",
        "  \"nbformat_minor\": 0,\n",
        "  \"metadata\": {\n",
        "    \"colab\": {\n",
        "      \"provenance\": [],\n",
        "      \"authorship_tag\": \"ABX9TyOxQkV82CvqHowpU5bVJH8V\",\n",
        "      \"include_colab_link\": true\n",
        "    },\n",
        "    \"kernelspec\": {\n",
        "      \"name\": \"python3\",\n",
        "      \"display_name\": \"Python 3\"\n",
        "    },\n",
        "    \"language_info\": {\n",
        "      \"name\": \"python\"\n",
        "    }\n",
        "  },\n",
        "  \"cells\": [\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"view-in-github\",\n",
        "        \"colab_type\": \"text\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"<a href=\\\"https://colab.research.google.com/github/srigit-dot/machine-learning/blob/main/KNN(Deep%20Learning).ipynb\\\" target=\\\"_parent\\\"><img src=\\\"https://colab.research.google.com/assets/colab-badge.svg\\\" alt=\\\"Open In Colab\\\"/></a>\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"execution_count\": 4,\n",
        "      \"metadata\": {\n",
        "        \"colab\": {\n",
        "          \"base_uri\": \"https://localhost:8080/\",\n",
        "          \"height\": 646\n",
        "        },\n",
        "        \"id\": \"dFXDUXlTFATJ\",\n",
        "        \"outputId\": \"aa4a8f89-3008-4b21-8dbe-8b2de0dfcdee\"\n",
        "      },\n",
        "      \"outputs\": [\n",
        "        {\n",
        "          \"output_type\": \"stream\",\n",
        "          \"name\": \"stdout\",\n",
        "          \"text\": [\n",
        "            \"Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\\n\",\n",
        "            \"\\n\",\n",
        "            \"Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\\n\",\n",
        "            \"* Running on public URL: https://386d2aa78b2326e927.gradio.live\\n\",\n",
        "            \"\\n\",\n",
        "            \"This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\\n\"\n",
        "          ]\n",
        "        },\n",
        "        {\n",
        "          \"output_type\": \"display_data\",\n",
        "          \"data\": {\n",
        "            \"text/plain\": [\n",
        "              \"<IPython.core.display.HTML object>\"\n",
        "            ],\n",
        "            \"text/html\": [\n",
        "              \"<div><iframe src=\\\"https://386d2aa78b2326e927.gradio.live\\\" width=\\\"100%\\\" height=\\\"500\\\" allow=\\\"autoplay; camera; microphone; clipboard-read; clipboard-write;\\\" frameborder=\\\"0\\\" allowfullscreen></iframe></div>\"\n",
        "            ]\n",
        "          },\n",
        "          \"metadata\": {}\n",
        "        },\n",
        "        {\n",
        "          \"output_type\": \"execute_result\",\n",
        "          \"data\": {\n",
        "            \"text/plain\": []\n",
        "          },\n",
        "          \"metadata\": {},\n",
        "          \"execution_count\": 4\n",
        "        }\n",
        "      ],\n",
        "      \"source\": [\n",
        "        \"import gradio as gr\\n\",\n",
        "        \"import numpy as np\\n\",\n",
        "        \"from sklearn.datasets import load_iris\\n\",\n",
        "        \"from sklearn.model_selection import train_test_split\\n\",\n",
        "        \"from sklearn.preprocessing import StandardScaler\\n\",\n",
        "        \"from sklearn.neighbors import KNeighborsClassifier\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Load the Iris dataset\\n\",\n",
        "        \"iris = load_iris()\\n\",\n",
        "        \"X = iris.data  # Features: sepal length, sepal width, petal length, petal width\\n\",\n",
        "        \"y = iris.target  # Target: flower species\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Split dataset into training and testing sets\\n\",\n",
        "        \"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Standardize the features\\n\",\n",
        "        \"scaler = StandardScaler()\\n\",\n",
        "        \"X_train_scaled = scaler.fit_transform(X_train)\\n\",\n",
        "        \"X_test_scaled = scaler.transform(X_test)\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Train the KNN model\\n\",\n",
        "        \"knn = KNeighborsClassifier(n_neighbors=3)\\n\",\n",
        "        \"knn.fit(X_train_scaled, y_train)\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Function to predict the species based on user input\\n\",\n",
        "        \"def predict_flower(sepal_length, sepal_width, petal_length, petal_width):\\n\",\n",
        "        \"    # Create the input array for prediction\\n\",\n",
        "        \"    input_data = np.array([[sepal_length, sepal_width, petal_length, petal_width]])\\n\",\n",
        "        \"\\n\",\n",
        "        \"    # Standardize the input data\\n\",\n",
        "        \"    scaled_input = scaler.transform(input_data)\\n\",\n",
        "        \"\\n\",\n",
        "        \"    # Predict the class (flower species)\\n\",\n",
        "        \"    prediction = knn.predict(scaled_input)\\n\",\n",
        "        \"\\n\",\n",
        "        \"    # Return the predicted flower species name\\n\",\n",
        "        \"    species = iris.target_names[prediction][0]\\n\",\n",
        "        \"    return f\\\"Predicted Flower Species: {species}\\\"\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Gradio interface for user interaction\\n\",\n",
        "        \"interface = gr.Interface(\\n\",\n",
        "        \"    fn=predict_flower,\\n\",\n",
        "        \"    inputs=[\\n\",\n",
        "        \"        gr.Slider(4.0, 8.0, step=0.1, value=5.0, label=\\\"Sepal Length (cm)\\\"),\\n\",\n",
        "        \"        gr.Slider(2.0, 5.0, step=0.1, value=3.0, label=\\\"Sepal Width (cm)\\\"),\\n\",\n",
        "        \"        gr.Slider(1.0, 7.0, step=0.1, value=4.0, label=\\\"Petal Length (cm)\\\"),\\n\",\n",
        "        \"        gr.Slider(0.1, 3.0, step=0.1, value=1.0, label=\\\"Petal Width (cm)\\\")\\n\",\n",
        "        \"    ],\\n\",\n",
        "        \"    outputs=\\\"text\\\",\\n\",\n",
        "        \"    title=\\\"KNN Flower Classification\\\",\\n\",\n",
        "        \"    description=\\\"Enter the features of a flower (sepal length, sepal width, petal length, petal width) to predict the species.\\\"\\n\",\n",
        "        \")\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Launch the Gradio app\\n\",\n",
        "        \"interface.launch()\\n\"\n",
        "      ]\n",
        "    }\n",
        "  ]\n",
        "}"
      ],
      "metadata": {
        "id": "NVPKhQF5KI7c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}